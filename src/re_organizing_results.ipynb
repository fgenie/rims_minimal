{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrected baselines\n",
    "ocw_ok_5 = \"outputs/n5_baseline_dt.ocw/chatgpt1106/model_selection_prompts/n5_baseline.jsonl\"\n",
    "ocw_ok_10 = \"outputs/n10_baseline_dt.ocw/chatgpt1106/model_selection_prompts/n10_baseline.jsonl\"\n",
    "gsm_ok_15 = \"outputs/n15_baseline_dt.gsm/chatgpt1106/model_selection_prompts/n15_baseline.jsonl\"\n",
    "math_ok_5 = \"outputs/n5_baseline_dt.math/chatgpt1106/model_selection_prompts/n5_baseline.jsonl\"\n",
    "\n",
    "\n",
    "# leftovers chatgpt1106\n",
    "GSM15=\"outputs_dgx/gsm8K_test_dt.gsm/chatgpt1106/model_selection_prompts/err_n15_baseline.jsonl\"\n",
    "OCW10=\"outputs_dgx/ocw_course_dt.ocw/chatgpt1106/model_selection_prompts/err_n10_baseline.jsonl\"\n",
    "OCW5=\"outputs/ocw_course_dt.ocw/chatgpt1106/model_selection_prompts/err_n5_baseline.jsonl\"\n",
    "MATH5=\"outputs/MATH-full_dt.math/chatgpt1106/model_selection_prompts/err_n5_baseline.jsonl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   NaN\n",
       "1   NaN\n",
       "2   NaN\n",
       "3   NaN\n",
       "4   NaN\n",
       "5   NaN\n",
       "6   NaN\n",
       "7   NaN\n",
       "Name: solmap, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import jsonlines as jsl\n",
    "\n",
    "right_err_pairs = [\n",
    "    (ocw_ok_5, OCW5),\n",
    "    (ocw_ok_10, OCW10),\n",
    "    (gsm_ok_15, GSM15),\n",
    "    (math_ok_5, MATH5)\n",
    "]\n",
    "\n",
    "df_r_e_pairs = [\n",
    "    (pd.DataFrame(jsl.open(right)), pd.DataFrame(jsl.open(err))) for right, err in right_err_pairs\n",
    "]\n",
    "\n",
    "# solmap, ansmap empty checked again\n",
    "df_r_e_pairs[0][1].solmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 0.8181818181818182, 0.9866666666666667]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sanity_check = [e[\"question\" if \"question\" in e.columns else \"problem\"].isin(r[\"question\" if \"question\" in e.columns else \"problem\"]).mean() for r,e in df_r_e_pairs]\n",
    "sanity_check # some of those were error pruned rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 rows to \n",
      "\toutputs/n5_baseline_dt.ocw/chatgpt1106/model_selection_prompts/n5_baseline_picked.jsonl\n",
      "23 rows to \n",
      "\toutputs/n10_baseline_dt.ocw/chatgpt1106/model_selection_prompts/n10_baseline_picked.jsonl\n",
      "18 rows to \n",
      "\toutputs/n15_baseline_dt.gsm/chatgpt1106/model_selection_prompts/n15_baseline_picked.jsonl\n",
      "296 rows to \n",
      "\toutputs/n5_baseline_dt.math/chatgpt1106/model_selection_prompts/n5_baseline_picked.jsonl\n"
     ]
    }
   ],
   "source": [
    "# make the files to run rims\n",
    "from pathlib import Path\n",
    "\n",
    "def pick_rows(src:pd.DataFrame=None, by:pd.DataFrame=None)->pd.DataFrame:\n",
    "    q_key = \"question\" if \"question\" in src.columns else \"problem\"\n",
    "    return src[src[q_key].isin(by[q_key])]\n",
    "\n",
    "target_paths = [ Path(r).parent/Path(r).name.replace(\"_baseline\", \"_baseline_picked\") for r,e in right_err_pairs]\n",
    "\n",
    "contents = [pick_rows(src=df_r, by=df_e) for df_r, df_e in df_r_e_pairs]\n",
    "\n",
    "for path, content in zip(target_paths, contents):\n",
    "    with jsl.open(path, \"w\") as writer:\n",
    "        writer.write_all(content.to_dict(orient=\"records\")) \n",
    "        print(f\"{len(content)} rows to \\n\\t{path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 23, 22, 300]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_err_rows = [len(e) for r,e in df_r_e_pairs]\n",
    "original_err_rows # 0, 0, 4, 4 loss. acceptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python run_inference.py rims_inference \\\n",
      "             --backbone chatgpt1106 \\\n",
      "             --gsm_jslf outputs/n5_baseline_dt.ocw/chatgpt1106/model_selection_prompts/n5_baseline_picked.jsonl \\\n",
      "             --n 5 \\\n",
      "             --dataset_type ocw \\\n",
      "             --n_jobs 8\n",
      "python run_inference.py rims_inference \\\n",
      "             --backbone chatgpt1106 \\\n",
      "             --gsm_jslf outputs/n10_baseline_dt.ocw/chatgpt1106/model_selection_prompts/n10_baseline_picked.jsonl \\\n",
      "             --n 10 \\\n",
      "             --dataset_type ocw \\\n",
      "             --n_jobs 8\n",
      "python run_inference.py rims_inference \\\n",
      "             --backbone chatgpt1106 \\\n",
      "             --gsm_jslf outputs/n15_baseline_dt.gsm/chatgpt1106/model_selection_prompts/n15_baseline_picked.jsonl \\\n",
      "             --n 15 \\\n",
      "             --dataset_type gsm \\\n",
      "             --n_jobs 8\n",
      "python run_inference.py rims_inference \\\n",
      "             --backbone chatgpt1106 \\\n",
      "             --gsm_jslf outputs/n5_baseline_dt.math/chatgpt1106/model_selection_prompts/n5_baseline_picked.jsonl \\\n",
      "             --n 5 \\\n",
      "             --dataset_type math \\\n",
      "             --n_jobs 8\n"
     ]
    }
   ],
   "source": [
    "cmds = [] \n",
    "for gsm_jslf, n, dataset_type in zip(target_paths, [5, 10, 15, 5], [\"ocw\", \"ocw\", \"gsm\", \"math\"]):\n",
    "    cmd = f\"python run_inference.py rims_inference \\\\\\n \\\n",
    "            --backbone chatgpt1106 \\\\\\n \\\n",
    "            --gsm_jslf {gsm_jslf} \\\\\\n \\\n",
    "            --n {n} \\\\\\n \\\n",
    "            --dataset_type {dataset_type} \\\\\\n \\\n",
    "            --n_jobs 8\"\n",
    "    cmds.append(cmd)\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (3381292144.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    ocw_ok_5_to=outputs/0_final_results/ocw_course_dt.ocw/chatgpt1106/model_selection_prompts/n5_baseline.jsonl\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "# FIXED_BASELINES --> no need to merge. \n",
    "\n",
    "mkdir -p outputs/0_final_results/ocw_course_dt.ocw/chatgpt1106/model_selection_prompts/\n",
    "mkdir -p outputs/0_final_results/gsm8K_test_dt.gsm/chatgpt1106/model_selection_prompts/\n",
    "mkdir -p outputs/0_final_results/MATH-full_dt.math/chatgpt1106/model_selection_prompts/\n",
    "\n",
    "ocw_ok_5=outputs/n5_baseline_dt.ocw/chatgpt1106/model_selection_prompts/n5_baseline.jsonl\n",
    "ocw_ok_5_to=outputs/0_final_results/ocw_course_dt.ocw/chatgpt1106/model_selection_prompts/n5_baseline.jsonl\n",
    "cp $ocw_ok_5 $ocw_ok_5_to\n",
    "\n",
    "ocw_ok_10=outputs/n10_baseline_dt.ocw/chatgpt1106/model_selection_prompts/n10_baseline.jsonl\n",
    "ocw_ok_10_to=outputs/0_final_results/ocw_course_dt.ocw/chatgpt1106/model_selection_prompts/n10_baseline.jsonl\n",
    "cp $ocw_ok_10 $ocw_ok_10_to\n",
    "\n",
    "gsm_ok_15=outputs/n15_baseline_dt.gsm/chatgpt1106/model_selection_prompts/n15_baseline.jsonl\n",
    "gsm_ok_15_to=outputs/0_final_results/gsm8K_test_dt.gsm/chatgpt1106/model_selection_prompts/n15_baseline.jsonl\n",
    "cp $gsm_ok_15 $gsm_ok_15_to\n",
    "\n",
    "math_ok_5=outputs/n5_baseline_dt.math/chatgpt1106/model_selection_prompts/n5_baseline.jsonl\n",
    "math_ok_5_to=outputs/0_final_results/MATH-full_dt.math/chatgpt1106/model_selection_prompts/n5_baseline.jsonl\n",
    "cp $math_ok_5 $math_ok_5_to\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 110\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prefix\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mocw_course\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m prefix\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMATH-full\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m prefix\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgsm8K_test\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    109\u001b[0m     newpathparts \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mparts[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 110\u001b[0m     newpath \u001b[38;5;241m=\u001b[39m \u001b[43mROOTDIR\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoinpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnewpathparts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     newpath\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/new_openai/lib/python3.11/pathlib.py:763\u001b[0m, in \u001b[0;36mPurePath.joinpath\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjoinpath\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m    758\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Combine this path with one or several arguments, and return a\u001b[39;00m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;124;03m    new path representing either a subpath (if all arguments are relative\u001b[39;00m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;124;03m    paths) or a totally different path (if one of the arguments is\u001b[39;00m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;124;03m    anchored).\u001b[39;00m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 763\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/new_openai/lib/python3.11/pathlib.py:531\u001b[0m, in \u001b[0;36mPurePath._make_child\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_child\u001b[39m(\u001b[38;5;28mself\u001b[39m, args):\n\u001b[0;32m--> 531\u001b[0m     drv, root, parts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    532\u001b[0m     drv, root, parts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flavour\u001b[38;5;241m.\u001b[39mjoin_parsed_parts(\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drv, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_root, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parts, drv, root, parts)\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_from_parsed_parts(drv, root, parts)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/new_openai/lib/python3.11/pathlib.py:493\u001b[0m, in \u001b[0;36mPurePath._parse_args\u001b[0;34m(cls, args)\u001b[0m\n\u001b[1;32m    491\u001b[0m     parts \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39m_parts\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 493\u001b[0m     a \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(a)\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    495\u001b[0m         \u001b[38;5;66;03m# Force-cast str subclasses to str (issue #21127)\u001b[39;00m\n\u001b[1;32m    496\u001b[0m         parts\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(a))\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not tuple"
     ]
    }
   ],
   "source": [
    "\n",
    "# FIXED + ORIGINAL RIMS \n",
    "# FIXED: find outputs/ -name \"n*baseline_dt*/**/*rims*.jsonl\" \n",
    "# ORIGINAL_RIMS results files\n",
    "\"\"\"\n",
    "\n",
    "find **/chatgpt1106 -name \"n*rims_T*.jsonl\"\n",
    "\n",
    "src/results_paths.txt\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd \n",
    "import jsonlines as jsl\n",
    "from pathlib import Path\n",
    "\n",
    "# original rims results files + picked files \n",
    "def check_and_merge_results(jslf1, jslf2):\n",
    "    \"\"\"\n",
    "    usually the jsonl records does not expected to overlap, but math result do. \n",
    "    I guess this comes from error: true with different reason than 429 error in math (rims run on ~error)\n",
    "    \"\"\"\n",
    "    # load and drop error lines first: expects most of overlaps will disappear.\n",
    "    df1, df2 = pd.read_json(jslf1, lines=True), pd.read_json(jslf2, lines=True)\n",
    "    df1_ = df1[~(df1.error)]\n",
    "    df2_ = df2[~(df2.error)]\n",
    "    print(\"dropped errors (jslf1, jslf2)\")\n",
    "    print(-len(df1_)+len(df1), len(df1))\n",
    "    print(-len(df2_)+len(df2), len(df2))\n",
    "\n",
    "    # check overlaps \n",
    "    q_key = \"question\" if \"question\" in df1.columns else \"problem\"  \n",
    "    overlap = (df1_[q_key].isin(df2_[q_key]))\n",
    "    print(f\"{overlap.sum()=} rows\")\n",
    "    df1__ = df1_[~overlap]\n",
    "\n",
    "    # merge\n",
    "    df_merged = pd.concat([df1__, df2_], axis=\"index\")    \n",
    "    \n",
    "    return df_merged.to_dict(orient=\"records\")\n",
    "\n",
    "\n",
    "# to merge rows... (from results_paths.txt)\n",
    "JSLF_PAIRS = {\n",
    "    \"math_n5_rims\":\n",
    "    [(\"outputs/MATH-full_dt.math/chatgpt1106/rims_math_p2c-cot.pal-p2c.pal-cot__.txt1/n5_rims_T0.5.jsonl\",\n",
    "     \"outputs/n5_baseline_dt.math/chatgpt1106/rims_math_p2c-cot.pal-p2c.pal-cot__.txt1/n5_rims_T0.5.jsonl\"),\n",
    "    (\"outputs/MATH-full_dt.math/chatgpt1106/rims_math_p2c-cot.pal-p2c.pal-cot__.txt1/n5_rims_T0.2.jsonl\",\n",
    "     \"outputs/n5_baseline_dt.math/chatgpt1106/rims_math_p2c-cot.pal-p2c.pal-cot__.txt1/n5_rims_T0.2.jsonl\"),\n",
    "    (\"outputs/MATH-full_dt.math/chatgpt1106/rims_math_p2c-cot.pal-p2c.pal-cot__.txt/n5_rims_T0.5.jsonl\",\n",
    "     \"outputs/n5_baseline_dt.math/chatgpt1106/rims_math_p2c-cot.pal-p2c.pal-cot__.txt/n5_rims_T0.5.jsonl\"),\n",
    "    (\"outputs/MATH-full_dt.math/chatgpt1106/rims_math_p2c-cot.pal-p2c.pal-cot__.txt/n5_rims_T0.2.jsonl\",\n",
    "     \"outputs/n5_baseline_dt.math/chatgpt1106/rims_math_p2c-cot.pal-p2c.pal-cot__.txt/n5_rims_T0.2.jsonl\")],\n",
    "\"ocw_n10_rims\":\n",
    "     [(\"outputs_dgx/ocw_course_dt.ocw/chatgpt1106/rims_ocw_p2c-cot.pal-p2c.pal-cot__.txt/n10_rims_T0.5.jsonl\",\n",
    "      \"outputs/n10_baseline_dt.ocw/chatgpt1106/rims_ocw_p2c-cot.pal-p2c.pal-cot__.txt/n10_rims_T0.5.jsonl\"),\n",
    "     (\"outputs_dgx/ocw_course_dt.ocw/chatgpt1106/rims_ocw_p2c-cot.pal-p2c.pal-cot__.txt/n10_rims_T0.2.jsonl\",\n",
    "      \"outputs/n10_baseline_dt.ocw/chatgpt1106/rims_ocw_p2c-cot.pal-p2c.pal-cot__.txt/n10_rims_T0.2.jsonl\"),\n",
    "     (\"outputs_dgx/ocw_course_dt.ocw/chatgpt1106/rims_ocw_p2c-cot.pal-p2c.cot-p2c__.txt/n10_rims_T0.5.jsonl\",\n",
    "      \"outputs/n10_baseline_dt.ocw/chatgpt1106/rims_ocw_p2c-cot.pal-p2c.cot-p2c__.txt/n10_rims_T0.5.jsonl\"),\n",
    "     (\"outputs_dgx/ocw_course_dt.ocw/chatgpt1106/rims_ocw_p2c-cot.pal-p2c.cot-p2c__.txt/n10_rims_T0.2.jsonl\",\n",
    "      \"outputs/n10_baseline_dt.ocw/chatgpt1106/rims_ocw_p2c-cot.pal-p2c.cot-p2c__.txt/n10_rims_T0.2.jsonl\")],\n",
    "\n",
    "\"gsm_n15_rims\":\n",
    "    [(\"outputs_dgx/gsm8K_test_dt.gsm/chatgpt1106/rewrote.p2c_gsm_pal2p2c.cot2p2c.cot2pal.txt/n15_rims_T0.2.jsonl\",\n",
    "      \"outputs/n15_baseline_dt.gsm/chatgpt1106/rewrote.p2c_gsm_pal2p2c.cot2p2c.cot2pal.txt/n15_rims_T0.2.jsonl\"),\n",
    "    (\"outputs_dgx/gsm8K_test_dt.gsm/chatgpt1106/rewrote.p2c_gsm_pal2p2c.cot2p2c.cot2pal.txt/n15_rims_T0.5.jsonl\",\n",
    "      \"outputs/n15_baseline_dt.gsm/chatgpt1106/rewrote.p2c_gsm_pal2p2c.cot2p2c.cot2pal.txt/n15_rims_T0.5.jsonl\"),\n",
    "    (\"outputs_dgx/gsm8K_test_dt.gsm/chatgpt1106/rewrote.p2c_gsm_newer_best_p2c2cot.pal2p2c.pal2cot.txt/n15_rims_T0.2.jsonl\",\n",
    "      \"outputs/n15_baseline_dt.gsm/chatgpt1106/rewrote.p2c_gsm_newer_best_p2c2cot.pal2p2c.pal2cot.txt/n15_rims_T0.2.jsonl\"),\n",
    "    (\"outputs_dgx/gsm8K_test_dt.gsm/chatgpt1106/rewrote.p2c_gsm_newer_best_p2c2cot.pal2p2c.pal2cot.txt/n15_rims_T0.5.jsonl\",\n",
    "      \"outputs/n15_baseline_dt.gsm/chatgpt1106/rewrote.p2c_gsm_newer_best_p2c2cot.pal2p2c.pal2cot.txt/n15_rims_T0.5.jsonl\"),\n",
    "    (\"outputs_dgx/gsm8K_test_dt.gsm/chatgpt1106/rewrote.p2c_gsm_cot2p2c.pal2cot.pal2p2c.txt/n15_rims_T0.2.jsonl\",\n",
    "      \"outputs/n15_baseline_dt.gsm/chatgpt1106/rewrote.p2c_gsm_cot2p2c.pal2cot.pal2p2c.txt/n15_rims_T0.2.jsonl\"),\n",
    "    (\"outputs_dgx/gsm8K_test_dt.gsm/chatgpt1106/rewrote.p2c_gsm_cot2p2c.pal2cot.pal2p2c.txt/n15_rims_T0.5.jsonl\",\n",
    "      \"outputs/n15_baseline_dt.gsm/chatgpt1106/rewrote.p2c_gsm_cot2p2c.pal2cot.pal2p2c.txt/n15_rims_T0.5.jsonl\")],\n",
    "\n",
    "\"ocw_n5_rims\":\n",
    "       [(\"outputs/n5_baseline_dt.ocw/chatgpt1106/rims_ocw_p2c-cot.pal-p2c.pal-cot__.txt/n5_rims_T0.5.jsonl\",\n",
    "     \"outputs/ocw_course_dt.ocw/chatgpt1106/rims_ocw_p2c-cot.pal-p2c.pal-cot__.txt/n5_rims_T0.5.jsonl\"),\n",
    "       (\"outputs/n5_baseline_dt.ocw/chatgpt1106/rims_ocw_p2c-cot.pal-p2c.pal-cot__.txt/n5_rims_T0.2.jsonl\",\n",
    "     \"outputs/ocw_course_dt.ocw/chatgpt1106/rims_ocw_p2c-cot.pal-p2c.pal-cot__.txt/n5_rims_T0.2.jsonl\"),\n",
    "       (\"outputs/n5_baseline_dt.ocw/chatgpt1106/rims_ocw_p2c-cot.pal-p2c.cot-p2c__.txt/n5_rims_T0.5.jsonl\",\n",
    "     \"outputs/ocw_course_dt.ocw/chatgpt1106/rims_ocw_p2c-cot.pal-p2c.cot-p2c__.txt/n5_rims_T0.5.jsonl\"),\n",
    "       (\"outputs/n5_baseline_dt.ocw/chatgpt1106/rims_ocw_p2c-cot.pal-p2c.cot-p2c__.txt/n5_rims_T0.2.jsonl\",\n",
    "     \"outputs/ocw_course_dt.ocw/chatgpt1106/rims_ocw_p2c-cot.pal-p2c.cot-p2c__.txt/n5_rims_T0.2.jsonl\")],\n",
    "}\n",
    "\n",
    "def get_prefix(path):\n",
    "    return Path(path).parts[1]\n",
    "\n",
    "\n",
    "ROOTDIR = Path(\"outputs/0_final_results\")\n",
    "\n",
    "for key, pairs in JSLF_PAIRS.items():\n",
    "    for jslf1, jslf2 in pairs:\n",
    "        jslf1, jslf2 = Path(jslf1), Path(jslf2)\n",
    "        assert Path(jslf1).name == Path(jslf2).name\n",
    "\n",
    "        for f in [jslf1, jslf2]:\n",
    "            prefix = get_prefix(f)\n",
    "            if prefix.startswith(\"ocw_course\") or prefix.startswith(\"MATH-full\") or prefix.startswith(\"gsm8K_test\"):\n",
    "                newpathparts = f.parts[1:]\n",
    "                newpath = ROOTDIR/\"/\".join(newpathparts)\n",
    "                newpath.parent.mkdir(parents=True, exist_ok=True)\n",
    "                break\n",
    "        assert prefix.startswith(\"ocw_course\") or prefix.startswith(\"MATH-full\") or prefix.startswith(\"gsm8K_test\")\n",
    "        \n",
    "        merged = check_and_merge_results(jslf1, jslf2)\n",
    "        with jsl.open(newpath, \"w\") as writer:\n",
    "            writer.write_all(merged)\n",
    "            print(f\"wrote {len(merged)} rows to \\n\\t{newpath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0_final_results'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make SC15, SC5, 10 with \n",
    "# run_modif_SC_results.py\n",
    "ROOTDIR.parts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_evaluation_new_n.py script for all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-organize the result files for later and analyses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare full script for sjjung to run "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
